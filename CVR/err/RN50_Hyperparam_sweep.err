module: loading 'python/3.7.4'
module: loading 'gcc/10.2'
module: gcc: "Note: loading the gcc module overrides the gcc version on the system.  If you want to revert to the version of gcc provided by the OS, unload the gcc module."
module: loading 'cuda/11.1.1'
module: cuda: To use: module load gcc/10.2
module: loading 'cudnn/8.2.0'
module: cudnn: To use: module load cuda/11.1.1 gcc/10.2
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/users/mlepori/.local/lib/python3.7/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /gpfs/scratch/mlepori/Compositional_Subnetworks/Models/resnet50/InCount_Hparams exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/users/mlepori/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/users/mlepori/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/users/mlepori/.local/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Global seed set to 0
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Missing logger folder: /users/mlepori/scratch/Compositional_Subnetworks/Models/resnet50/InCount_Hparams/lightning_logs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type   | Params
------------------------------------
0 | backbone | ResNet | 23.5 M
1 | mlp      | MLP    | 4.5 M 
------------------------------------
27.9 M    Trainable params
0         Non-trainable params
27.9 M    Total params
111.654   Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
Global seed set to 0
Global seed set to 0
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
